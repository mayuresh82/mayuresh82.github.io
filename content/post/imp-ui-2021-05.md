---
title: "Building User Interfaces for Network Automation"
layout: post
date: 2021-06-10T09:00:00-08:00
published: true
author: "mayuresh82"
subtitle: "Exploring ways to implement user interfaces for network automation frameworks"
image: "/img/epe-pt1.jpg"
tags:
    - ui
    - react
    - network-automation
URL: "/2021/06/10/building-uis-network-automation"
categories: [ "General" ]
---

# The importance of User Interfaces for Network Automation

One of the least talked about aspects of network automation workflows is the ability to interface with the different tools and frameworks that enable these workflows. Consider a scenario where you are part of a small team of Network Engineers in a small company that has a small but growing customer base. You realize the need to automate your device and link provisioning workflows and hack up a few Python scripts (or Ansible playbooks if you prefer) that get the job done in the beginning. 

Over time, your company grows exponentially and so does your production network environment. You now have a dedicated team of engineers solely responsible for network deployment and bandwidth provisioning. In such a scenario, it becomes imperative to allow other engineers to be able to run automation workflows for device management and provisioning; and careful thought must be given to the end user experience in order to ensure that your automation tools dont act as blockers for the overall growth of company infrastructure. This still leaves you, the original author of those frameworks in charge of maintaining these tools but you are now able to offload trivial and repetetive tasks to other teams so you can focus on higher priority problems. This post explores how one can approach the problem initially and evolve the user interface over time to meet this goal of enablement.

## Day 1: The CLI

During your initial foray into automating a production network, you often want to keep things as simple as possible. In fact, it is a good idea to focus as much as possible on the business goals and logic while quickly throwing together a trivial way to accept user input or provide user interaction with your tool. Consider the example of pushing a configuration to a router in the network. For the sake of this discussion, we can ignore the actual implementation details since they are not very relevant. Assuming that we have some Python code called `push_config.py` that does the job behind the scenes, your day 1 implementation might just be a simple argument parser using the built in `sys` module that accepts, at a minimum, the IP address of the device and its credentials:

```python
import sys

def push_config(router_ip, username, password, config):
    # your logic here
    return True

if __name__ == '__main__':
    router_ip = sys.argv[1]
    username = sys.argv[2]
    password = sys.argv[3]
    config_file = sys.argv[4]
    with open('config_file') as f:
        config = f.read()
    return push_config(router_ip, username, password, config)
```

The script can then be invoked using `python`:
```
python push_config.py 10.1.1.200 userfoo passfoo
```

Of course the problem with this approach is that it does not scale with a growing number of devices and scripts to maintain. It is also fragile and requires a lot of custom error handling and sanity checking. This becomes a bigger problem when you try and offload the scripts onto other engineers to help with day today config pushes. In the real world, frameworks like Nornir take care of the inventory management for you by providing a way to build inventories dynamically or load them via inventory files, but if you are just starting out with ad hoc scripts, using some well known Python modules such as `argparse`, `optparse` or the more powerful [Click](https://click.palletsprojects.com/en/8.0.x/) project can alleviate some of the problems with the simple `argv` based approach. These libraries make your tooling a lot more user friendly and allow the use of helpful annotations and usage instructions that allow other teams to easily operate the network.


## Day 2: The API

The CLI approach works well when you have a confined domain of engineers operating and running your tools. Lets say that over time, you expand the functionality of your Python scripts to also fetch critical pieces of information from network devices for the purposes of analysis or monitoring. You are now also required to make this information accessible to application owners so they can incorporate network data into their own workflows. Your tooling is now more mission critical to the growth of the organization or company infrastructure, and the simple CLI interface does not work for this use case - especially when application owners need a programmatic way of ingesting your data. Enter the Application Programming Interface or API. An API allows you to convert your tooling into a service or a framework via a client-server model in which the server exposes "endpoints" that clients can invoke remotely in order to perform specific tasks or run scripts in the backend. A perfect example of this is a RESTful API which uses HTTP requests to access and use data.

Considering our business use case, remember that we now have multiple teams using our tooling and we would still need to allow CLI access to our deployment team in order to not break their workflows. Do we then need the additional overhead of maintaining not just the original CLI based execution logic as well as a parallel REST API that allows for remote execution ? The answer is that we do not, and therein lies the idea of API driven frameworks. In a nutshell, you write all your tooling such that any and all user / client interaction happens by means of the API. 



Going with our example above, here is a short snippet of code that creates a basic HTTP server using the Flask Python framework and allows running our config push tool via the API. The CLI and REST API are disaggregated, maintained as two separate pieces of code. This allows constraining all the business logic in a central API (possibly residing on a machine in a datacenter) while distributing the CLI code to the end users to run via their personal computers. A change or a fix to one can be made without affecting the other.

<span style="font-family:monospace">api.py:</span>

```python
from flask import Flask
app = Flask(__name__)

@app.route('/pushConfig', methods=['POST'])
def push_config():
    body = request.json
    ip = body['ip_address']
    username = body['username']
    password = body['password']
    config = body['config']

    # your logic here
    return True
```

<span style="font-family:monospace">push_config.py:</span>

```python
import requests
import click

api_url = 'http://localhost:8080'

@click.command()
@click.option('--username', help='Router username')
@click.option('--password', help='Router password')
@click.argument('router_ip')
@click.argument('config_file')
def push_config(u, p, ip, config_file):
    with open('config_file') as f:
        config = f.read()
    body = {
        'ip_address': ip,
        'username': u,
        'password': p,
        'config': config,
    }
    resp = requests.post(api_url + '/pushConfig', json=body)
    resp.raise_for_status()

```

As you can tell, the CLI program now interacts directly with the API over the network in order to push the config. This is known as a Remote Procedure Call or RPC , where you are calling a "procedure" or a function/method in this case remotely over the network using an API that the remote server exposes. Notice how the function name is part of the URL and the function "arguments" are passed as the request body. Note that there are other less widely used RPC mechanisms out there such as JSON RPC or SOAP but I would stay clear of them. If you are just getting started - REST is best.

## Day 3: The UI

Fast forward six more months, and your operations team is now involved in several different projects. Pushing out configs to devices is now seamless and efficient thanks to the framework you delivered. In fact, it has worked well enough for the operations team to delegate simple circuit turn-up tasks out to field engineers. However, the field engineers don't have much clue about what a piece of configuration does nor how it gets generated. All they are concerned with is pushing out a given piece of configuration to a set of devices in the quickest possible manner. Would't it be great if there were a web interface where an authorized person could simply upload a piece of configuration (handed to them by some other means) and press a button to push that out to the given devices ? 

Because we have made our framework API driven, a web UI can be easily bolted on to our framework. It becomes just another consumer of our API, similar to our already existing CLI tool. Of course, this requires a bit of HTML or Javascript knowledge but it is a worthwhile investment in my humble opinion - one whose dividends quickly pay off. There are a couple of methods available to added a web UI to our framework:
